{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"M2 model.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":17999,"sourceType":"datasetVersion","datasetId":9726}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"id":"8pXzMXHqFe_m","outputId":"a78928f0-b386-40c2-cc3f-cce3929e7fe9","execution":{"iopub.status.busy":"2023-11-30T09:26:15.408661Z","iopub.execute_input":"2023-11-30T09:26:15.408993Z","iopub.status.idle":"2023-11-30T09:26:15.788368Z","shell.execute_reply.started":"2023-11-30T09:26:15.408965Z","shell.execute_reply":"2023-11-30T09:26:15.787331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset\nWe run through the following steps:\n1. Import the dataset from Kaggle and load into a `pd.DataFrame`\n2. Extract the images and labels from the `pd.DataFrame`","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/az-handwritten-alphabets-in-csv-format/A_Z Handwritten Data.csv\")\nX = data.drop(columns=\"0\")\ny = data[\"0\"].astype(\"float32\")","metadata":{"execution":{"iopub.status.busy":"2023-11-30T09:34:07.308928Z","iopub.execute_input":"2023-11-30T09:34:07.309281Z","iopub.status.idle":"2023-11-30T09:34:42.742570Z","shell.execute_reply.started":"2023-11-30T09:34:07.309255Z","shell.execute_reply":"2023-11-30T09:34:42.741753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom torch.utils.data import Dataset\n\n\nclass HandwritingDataset(Dataset):\n    def __init__(self, X: pd.DataFrame, y: pd.Series, transform=None, target_transform=None):\n        self.img_labels = y\n        self.images = [row.reshape(28, 28) for _, row in X.iterrows()]\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        label = self.img_labels.iloc[idx, 1]\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return image, label\n\n\ntrain_dataset = HandwritingDataset(X_train, y_train)\ntest_dataset = HandwritingDataset(X_train, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision\n\ntransform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n\n# mnist data\ntrain_dataset = torchvision.datasets.MNIST(root='./data/mnist', train=True, transform=transform, download=True)\ntest_dataset = torchvision.datasets.MNIST(root='./data/mnist', train=False, transform=transform, download=True)\ninput_size = 28","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:44:31.362600Z","iopub.execute_input":"2023-11-30T12:44:31.363352Z","iopub.status.idle":"2023-11-30T12:44:31.397301Z","shell.execute_reply.started":"2023-11-30T12:44:31.363316Z","shell.execute_reply":"2023-11-30T12:44:31.396312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"di6weTSlMpgA","execution":{"iopub.status.busy":"2023-11-30T12:44:31.398913Z","iopub.execute_input":"2023-11-30T12:44:31.399223Z","iopub.status.idle":"2023-11-30T12:44:31.404111Z","shell.execute_reply.started":"2023-11-30T12:44:31.399195Z","shell.execute_reply":"2023-11-30T12:44:31.403193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# put into batches\nbatch_size = 64\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T12:44:31.405349Z","iopub.execute_input":"2023-11-30T12:44:31.405615Z","iopub.status.idle":"2023-11-30T12:44:31.415471Z","shell.execute_reply.started":"2023-11-30T12:44:31.405590Z","shell.execute_reply":"2023-11-30T12:44:31.414773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VAE(nn.Module):\n    def __init__(self, input_size:int, num_filters:int, num_latent_var: int):\n        super(VAE, self).__init__()\n        self.input_size = input_size\n        self.num_latent_var = num_latent_var\n        self.input_encoder = nn.Sequential(\n                    nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=4, stride=2, padding=1),\n                    nn.ReLU(),\n                    nn.Conv2d(in_channels=num_filters, out_channels=num_filters, kernel_size=2, stride=1, padding=1),\n                    nn.ReLU(),   \n                    nn.Conv2d(in_channels=num_filters, out_channels=1, kernel_size=4, stride=2, padding=1),\n                    nn.ReLU(),\n                    nn.Flatten()\n                    )\n        \n        encoder_output_dim = (7,7)\n        encoder_output_size = int(np.prod(encoder_output_dim))\n        self.y_encoder = nn.Sequential(nn.Linear(encoder_output_size, 128), nn.ReLU(), nn.Linear(128, 10))\n        self.z_mean = nn.Linear(encoder_output_size, num_latent_var)\n        self.log_z_var = nn.Linear(encoder_output_size, num_latent_var)\n\n        self.y_decoder = nn.Sequential(nn.Linear(10, 128), nn.ReLU(), nn.Linear(128, encoder_output_size), nn.ReLU())\n        self.z_decoder = nn.Linear(num_latent_var, encoder_output_size)\n\n        self.output_decoder = nn.Sequential(\n            nn.Unflatten(1, (1, *encoder_output_dim)),\n            nn.ConvTranspose2d(in_channels=1, out_channels=num_filters, kernel_size=4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(in_channels=num_filters, out_channels=num_filters, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(in_channels=num_filters, out_channels=1, kernel_size=4, stride=2, padding=1),\n        )\n\n    def encode(self, x):\n        x = self.input_encoder(x)\n        y_pred = self.y_encoder(x)\n        z_mean = self.z_mean(x)\n        log_z_var = self.log_z_var(x)\n        return y_pred, z_mean, log_z_var\n\n    def forward(self, x):\n        y_pred, z_mean, log_z_var = self.encode(x)\n        std = log_z_var.mul(0.5).exp_()\n        epsilon = torch.randn(*z_mean.size()).to(device)\n        z = z_mean + std * epsilon\n        x_hat = self.decode(z, y_pred.softmax(axis=-1))\n        return x_hat, z_mean, log_z_var, y_pred\n\n    def decode(self, z, y):\n        x = self.z_decoder(z) + self.y_decoder(y)\n        return self.output_decoder(x)\n\n    def loss(self, x, y):\n        x_hat, z_mean, log_z_var, y_pred = self.forward(x)\n        cat_loss = nn.CrossEntropyLoss()(y_pred, y)\n        recon_loss = nn.BCEWithLogitsLoss()(x_hat, x)\n        kl_div_loss = -0.5 * torch.sum(1 + log_z_var - z_mean.pow(2) - log_z_var.exp()) / x.shape[0]\n        return cat_loss, recon_loss, kl_div_loss","metadata":{"id":"1nnmb13qPPSf","execution":{"iopub.status.busy":"2023-11-30T15:49:18.155996Z","iopub.execute_input":"2023-11-30T15:49:18.156929Z","iopub.status.idle":"2023-11-30T15:49:18.174268Z","shell.execute_reply.started":"2023-11-30T15:49:18.156886Z","shell.execute_reply":"2023-11-30T15:49:18.173467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = VAE(input_size=input_size, num_filters=32, num_latent_var=64).to(device)\noptimiser = torch.optim.Adam(model.parameters())","metadata":{"id":"TFY_b3jnc4YF","execution":{"iopub.status.busy":"2023-11-30T15:49:18.181401Z","iopub.execute_input":"2023-11-30T15:49:18.181744Z","iopub.status.idle":"2023-11-30T15:49:18.195870Z","shell.execute_reply.started":"2023-11-30T15:49:18.181716Z","shell.execute_reply":"2023-11-30T15:49:18.194982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\n\nfor epoch in range(1, num_epochs + 1):\n    minloss = 1\n    running_kl_div_loss = 0\n    running_recons_loss = 0\n    running_cat_loss = 0\n    num_images = 0\n    for i, (img, label) in enumerate(train_loader):\n        img = img.to(device)\n        label = label.to(device)\n        optimiser.zero_grad()\n        cat_loss, recons_loss, kl_div_loss = model.loss(img, label)\n        loss =  0.1 * cat_loss + recons_loss + epoch * 0.001 * kl_div_loss\n        loss.backward()\n        optimiser.step()\n        running_cat_loss = running_cat_loss + cat_loss.item() * len(img)\n        running_recons_loss = running_recons_loss + recons_loss.item() * len(img)\n        running_kl_div_loss = running_kl_div_loss +  kl_div_loss.item() * len(img)\n\n        num_images = num_images + len(img)\n    print(\n        'epoch: '\n        + str(epoch)\n        + ' cat_loss: '\n        + str(running_cat_loss / num_images)\n        + ' recons_loss: '\n        + str(running_recons_loss / num_images)\n        + ' kl_div_loss: '\n        + str(running_kl_div_loss / num_images)\n    )","metadata":{"id":"S3TZJjYCeYX5","outputId":"2fe0e8a5-fa9b-4c48-86c3-b9a235a93429","execution":{"iopub.status.busy":"2023-11-30T15:49:18.227163Z","iopub.execute_input":"2023-11-30T15:49:18.227442Z","iopub.status.idle":"2023-11-30T15:51:10.529808Z","shell.execute_reply.started":"2023-11-30T15:49:18.227416Z","shell.execute_reply":"2023-11-30T15:51:10.528783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Assessing model accuracy\nWe can evaluate the binary accuracy of the reconstructed images.","metadata":{}},{"cell_type":"code","source":"from torchmetrics.classification import Accuracy\n\nx_truths = []\nx_recons = [] \nz_means = []\nlog_z_vars = []\ny_truths = []\ny_preds = []\ncat_accuracies = []\nrecon_accuracies = []\n\ncat_metric = Accuracy(task='multiclass', num_classes=10)\nrecon_metric = Accuracy(task='binary', threshold=0.5)\n\nfor im, y_true in test_loader:\n    x_recon, z_mean, log_z_var, ysoft = model.forward(im.to(device))\n    _,y_pred  = torch.max(ysoft, 1)\n    x_truths.append(im)\n    x_recons.append(x_recon)\n    z_means.append(z_mean)\n    log_z_vars.append(log_z_var)\n    y_truths.append(y_true)\n    y_preds.append(y_pred)\n\n    cat_accuracies.append(cat_metric(y_pred.cpu(), y_true))\n    recon_accuracies.append(recon_metric(x_recon.cpu(), im>0.5))\n    \n\nprint(\"Cat. acc: {}\".format(sum(cat_accuracies)/len(cat_accuracies)))\nprint(\"Recon. acc: {}\".format(sum(recon_accuracies)/len(recon_accuracies)))","metadata":{"id":"Rn4bYw3hmkEW","execution":{"iopub.status.busy":"2023-11-30T15:51:10.531512Z","iopub.execute_input":"2023-11-30T15:51:10.531840Z","iopub.status.idle":"2023-11-30T15:51:12.189764Z","shell.execute_reply.started":"2023-11-30T15:51:10.531786Z","shell.execute_reply":"2023-11-30T15:51:12.188782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can get a more qualitative assessment by comparing the original and reconstructed images.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\nfig = plt.figure(figsize=(8.0, 10.0))\ngrid = ImageGrid(fig, 111, nrows_ncols=(2, 10), axes_pad=0.05)\n\nfor ax,im, y_true in zip(grid[:10], x_truths[0].cpu().detach(), y_truths[0].cpu().detach()):\n    ax.imshow(im.squeeze(), cmap='gray')\n    \nfor ax, im, y_pred in zip(grid[10:], x_recons[0].cpu().detach(), y_preds[0].cpu().detach()):\n    ax.imshow(im.squeeze().sigmoid(), cmap='gray')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T15:52:10.635129Z","iopub.execute_input":"2023-11-30T15:52:10.635760Z","iopub.status.idle":"2023-11-30T15:52:14.122087Z","shell.execute_reply.started":"2023-11-30T15:52:10.635725Z","shell.execute_reply":"2023-11-30T15:52:14.121145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generation of hand-writing\nLet us now use the decoder to general some artificial handwriting.\n- Determine the hand-writing style (in terms of latent variables) from the first 6 items in the test set\n- Generate the digits 1-10 for each of these styles","metadata":{}},{"cell_type":"code","source":"labels = torch.arange(0, 10).reshape(-1,1).tile(1,6).flatten()\ny_plot = nn.functional.one_hot(labels).float().to(device)\n\ndef _sample_latent_var(z_mean:torch.Tensor, log_z_var:torch.Tensor)->torch.Tensor:\n    e = 0*torch.randn(*z_mean.shape).to(device)\n    std = log_z_var.mul(0.5).exp_()\n    return z_mean + e * std\n\nz_mean_to_plot = z_means[0][:6]\nlog_z_var_to_plot = log_z_vars[0][:6]\nz_plot = _sample_latent_var(z_mean_to_plot, log_z_var_to_plot).tile(10,1)\ngenerated_images = model.decode(z_plot, y_plot).sigmoid().reshape(-1, input_size, input_size)\n","metadata":{"id":"6-vo2ULmnLlV","execution":{"iopub.status.busy":"2023-11-30T15:51:14.055212Z","iopub.execute_input":"2023-11-30T15:51:14.055891Z","iopub.status.idle":"2023-11-30T15:51:14.065918Z","shell.execute_reply.started":"2023-11-30T15:51:14.055850Z","shell.execute_reply":"2023-11-30T15:51:14.065056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(15.0, 10.0))\ngrid = ImageGrid(fig, 121, nrows_ncols=(10, 6), axes_pad=0.05)\n\nfor ax, im in zip(grid, generated_images.cpu().detach()):\n    ax.imshow(im, cmap='gray')\n\nplt.show()","metadata":{"id":"mF1DpZA7W48o","outputId":"c5230074-5f24-43fc-eb90-4523f2300015","execution":{"iopub.status.busy":"2023-11-30T15:51:14.067039Z","iopub.execute_input":"2023-11-30T15:51:14.067380Z","iopub.status.idle":"2023-11-30T15:51:24.255761Z","shell.execute_reply.started":"2023-11-30T15:51:14.067351Z","shell.execute_reply":"2023-11-30T15:51:24.254737Z"},"trusted":true},"execution_count":null,"outputs":[]}]}