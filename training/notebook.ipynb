{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "8pXzMXHqFe_m",
    "outputId": "a78928f0-b386-40c2-cc3f-cce3929e7fe9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/A_Z Handwritten Data.csv\")\n",
    "X = data.drop(columns=\"0\")\n",
    "y = data[\"0\"].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class HandwritingDataset(Dataset):\n",
    "    def __init__(self, X: pd.DataFrame, y: pd.Series, transform=None, target_transform=None):\n",
    "        self.img_labels = y\n",
    "        self.images = [row.reshape(28, 28) for _, row in X.iterrows()]\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "train_dataset = HandwritingDataset(X_train, y_train)\n",
    "test_dataset = HandwritingDataset(X_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "# mnist data\n",
    "train_dataset = torchvision.datasets.MNIST(root='data/mnist', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='data/mnist', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "di6weTSlMpgA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put into batches\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1nnmb13qPPSf"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, num_latent_var: int):\n",
    "        super(VAE, self).__init__()\n",
    "        self.num_latent_var = num_latent_var\n",
    "        self.input_encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1),\n",
    "            nn.Conv2d(in_channels=4, out_channels=4, kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=4, out_channels=1, kernel_size=2, stride=1),\n",
    "        )\n",
    "        self.y_encoder = nn.Sequential(nn.Linear(11 * 11, 128), nn.ReLU(), nn.Linear(128, 10), nn.Softmax(dim=1))\n",
    "        self.z_mean = nn.Linear(11 * 11, num_latent_var * num_latent_var)\n",
    "        self.log_z_var = nn.Linear(11 * 11, num_latent_var * num_latent_var)\n",
    "\n",
    "        self.y_decoder = nn.Sequential(nn.Linear(10, 128), nn.ReLU(), nn.Linear(128, 11 * 11))\n",
    "        self.z_decoder = nn.Linear(num_latent_var * num_latent_var, 11 * 11)\n",
    "\n",
    "        self.output_decoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=2, stride=1),\n",
    "            nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            nn.Conv2d(in_channels=4, out_channels=4, kernel_size=2, stride=1),\n",
    "            nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            nn.Conv2d(in_channels=4, out_channels=1, kernel_size=1, stride=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.input_encoder(x)\n",
    "        y_pred = self.y_encoder(x.reshape(x.shape[0], 11 * 11))\n",
    "        z_mean = self.z_mean(x.reshape(-1, 11 * 11))\n",
    "        log_z_var = self.log_z_var(x.reshape(-1, 11 * 11))\n",
    "        return y_pred, z_mean, log_z_var\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred, z_mean, log_z_var = self.encode(x)\n",
    "        std = log_z_var.mul(0.5).exp_()\n",
    "        epsilon = torch.randn(*z_mean.size()).to(device)\n",
    "        z = z_mean + std * epsilon\n",
    "        x_hat = self.decode(z, y_pred)\n",
    "        return x_hat, z_mean, log_z_var, y_pred\n",
    "\n",
    "    def decode(self, z, y):\n",
    "        y_decoder_input = self.y_decoder(y).reshape(-1, 1, 11, 11)\n",
    "        z_decoder_input = self.z_decoder(z).reshape(-1, 1, 11, 11)\n",
    "        return self.output_decoder(y_decoder_input + z_decoder_input)\n",
    "\n",
    "    def loss(self, x, y):\n",
    "        x_hat, z_mean, log_z_var, y_pred = self.forward(x)\n",
    "        categorisation_loss = nn.CrossEntropyLoss()(y_pred, y)\n",
    "        reconstruction_loss = nn.BCELoss()(x_hat, x)\n",
    "        kl_div_loss = -0.5 * torch.sum(1 + log_z_var - z_mean.pow(2) - log_z_var.exp()) / x.shape[0]\n",
    "        return categorisation_loss, reconstruction_loss, kl_div_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFY_b3jnc4YF"
   },
   "outputs": [],
   "source": [
    "model = VAE(num_latent_var=2).to(device)\n",
    "optimiser = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "S3TZJjYCeYX5",
    "outputId": "2fe0e8a5-fa9b-4c48-86c3-b9a235a93429"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    minloss = 1\n",
    "    running_kl_loss = 0\n",
    "    running_recons_loss = 0\n",
    "    running_cat_loss = 0\n",
    "    num_images = 0\n",
    "    for i, (img, label) in enumerate(train_loader):\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        optimiser.zero_grad()\n",
    "        cat_loss, recons_loss, kl_loss = model.loss(img, label)\n",
    "        loss = recons_loss + 0.1 * cat_loss + epoch * 0.001 * kl_loss\n",
    "        optimiser.backward()\n",
    "        optimiser.step()\n",
    "        running_cat_loss = running_cat_loss + cat_loss.item() * len(img)\n",
    "        running_recons_loss = running_recons_loss + recons_loss.item() * len(img)\n",
    "        running_kl_loss = running_kl_loss + kl_loss.item() * len(img)\n",
    "\n",
    "        num_images = num_images + len(img)\n",
    "    print(\n",
    "        'epoch: '\n",
    "        + str(epoch)\n",
    "        + ' cat_loss: '\n",
    "        + str(running_cat_loss / num_images)\n",
    "        + ' recons_loss: '\n",
    "        + str(running_recons_loss / num_images)\n",
    "        + ' kl_loss: '\n",
    "        + str(running_kl_loss / num_images)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQLTaY8XWTPt"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rn4bYw3hmkEW"
   },
   "outputs": [],
   "source": [
    "recons, z_mean, log_z_var, ysoft = 0, 0, 0, 0\n",
    "for im, l in test_loader:\n",
    "    recons, z_mean, log_z_var, ysoft = model.forward(im.to(device))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69fadMwkk5z-"
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(10):\n",
    "    for j in range(6):\n",
    "        labels.append(i)\n",
    "labels = torch.Tensor(np.array(labels)).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6-vo2ULmnLlV"
   },
   "outputs": [],
   "source": [
    "zl = []\n",
    "for i in range(10):\n",
    "    e = torch.randn(6, 11 * 11)\n",
    "    std = log_z_var[:6].mul(0.5).exp_()\n",
    "    z = z_mean[:6].cpu().detach() + e * std.cpu().detach()\n",
    "    zl.append(np.array(z))\n",
    "zl = np.array(zl)\n",
    "zl = torch.Tensor(zl.reshape(60, 49)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "colab_type": "code",
    "id": "mF1DpZA7W48o",
    "outputId": "c5230074-5f24-43fc-eb90-4523f2300015"
   },
   "outputs": [],
   "source": [
    "imgs = model.decode(labels, zl).cpu().detach().reshape(60, 28, 28)\n",
    "\n",
    "plt.gray()\n",
    "fig = plt.figure(figsize=(10.0, 6.0))\n",
    "grid = ImageGrid(\n",
    "    fig,\n",
    "    111,  # similar to subplot(111)\n",
    "    nrows_ncols=(10, 6),  # creates 2x2 grid of axes\n",
    "    axes_pad=0.05,  # pad between axes in inch.\n",
    ")\n",
    "\n",
    "for ax, im in zip(grid, imgs):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "M2 model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
